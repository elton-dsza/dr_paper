{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animated-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "athletic-elements",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/mnt/sdb/DATASETS/diabetic_retinopathy/trainLabels.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chemical-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_series = pd.Series(df_train['level'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crucial-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size1 = 512\n",
    "im_size2 = 512\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disabled-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Size: 35126 Old Size: 750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'level'}>,\n",
       "        <AxesSubplot:title={'center':'eye'}>]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Balancing dataset\n",
    "df_train_eye = df_train\n",
    "df_train_eye['eye'] = df_train['image'].map(lambda x: 1 if x.split('_')[-1]=='left' else 0)\n",
    "\n",
    "raw_train_df = df_train_eye.groupby(['level', 'eye']).apply(lambda x: x.sample(75, replace = True)\n",
    "                                                      ).reset_index(drop = True)\n",
    "print('New Data Size:', df_train.shape[0], 'Old Size:', raw_train_df.shape[0])\n",
    "raw_train_df[['level', 'eye']].hist(figsize = (10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "celtic-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19067_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23085_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5154_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25770_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30875_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  level\n",
       "0  19067_right      0\n",
       "1  23085_right      0\n",
       "2   5154_right      0\n",
       "3  25770_right      0\n",
       "4  30875_right      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del raw_train_df['eye']\n",
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inside-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:56<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "for f, breed in tqdm(raw_train_df.values):\n",
    "\n",
    "    if type(cv2.imread('/mnt/sdb/DATASETS/diabetic_retinopathy/train/{}.jpeg'.format(f)))==type(None):\n",
    "        continue\n",
    "    else:\n",
    "        img = cv2.imread('/mnt/sdb/DATASETS/diabetic_retinopathy/train/{}.jpeg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size1, im_size2)))\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)#cv2.COLOR_BGR2HSV)\n",
    "#         cv2.imshow('show',img)\n",
    "#         cv2.waitKey(0)\n",
    "#         x_train.append(cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), (im_size1, im_size2)))\n",
    "#         cv2.imshow('show',img)\n",
    "#         cv2.waitKey(0)\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "\n",
    "np.save('x_train2',x_train)\n",
    "np.save('y_train2',y_train)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equal-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train2.npy')\n",
    "y_train = np.load('y_train2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "native-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/mnt/sdb/DATASETS/diabetic_retinopathy/x_train2',x_train)\n",
    "np.save('/mnt/sdb/DATASETS/diabetic_retinopathy/y_train2',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polished-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = np.array(y_train, np.uint8)\n",
    "x_train_raw = np.array(x_train, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "together-battle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 512, 512, 3)\n",
      "(750, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gentle-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, train_labels, valid_labels = train_test_split(x_train_raw, y_train_raw, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naughty-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spare-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 512, 512, 3)\n",
      "(375, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "training_images = X_train\n",
    "testing_images = X_valid\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Create an ImageDataGenerator and do Image Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    ")\n",
    "    \n",
    "# Keep These\n",
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "# print(X_train.shape)\n",
    "# print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accessible-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Functional)       (None, 14, 14, 2048) 21802784    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 2048) 8192        inception_v3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 2048) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 64)   131136      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 16)   1040        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 8)    136         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 1)    9           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 14, 14, 2048) 0           conv2d_97[0][0]                  \n",
      "                                                                 batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1)            0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "RescaleGAP (Lambda)             (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           RescaleGAP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            645         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,206,214\n",
      "Trainable params: 399,334\n",
      "Non-trainable params: 21,806,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16 as PTModel\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2 as PTModel\n",
    "from keras.applications.inception_v3 import InceptionV3 as PTModel\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "in_lay = Input((512, 512, 3))\n",
    "base_pretrained_model = PTModel(input_shape =  (512, 512, 3), include_top = False, weights = None)\n",
    "base_pretrained_model.trainable = False\n",
    "pt_depth = (512, 512, 3)\n",
    "pt_features = base_pretrained_model(in_lay)\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "\n",
    "attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "\n",
    "\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.25)(gap)\n",
    "dr_steps = Dropout(0.25)(Dense(128, activation = 'relu')(gap_dr))\n",
    "out_layer = Dense(5, activation = 'softmax')(dr_steps)\n",
    "retina_model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "\n",
    "\n",
    "\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "def top_2_accuracy(in_gt, in_pred):\n",
    "    return top_k_categorical_accuracy(in_gt, in_pred, k=2)\n",
    "\n",
    "retina_model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy',\n",
    "                           metrics = ['categorical_accuracy', top_2_accuracy])\n",
    "retina_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "advisory-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('retina')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.000001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) \n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "geological-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure generators\n",
    "train_gen = train_datagen.flow(\n",
    "    training_images,\n",
    "    train_labels,\n",
    "    batch_size=5\n",
    ")\n",
    "\n",
    "val_gen = validation_datagen.flow(\n",
    "    testing_images,\n",
    "    valid_labels,\n",
    "    batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "neither-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "documentary-butterfly",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 51s 652ms/step - loss: 1.3820 - categorical_accuracy: 0.7452 - top_2_accuracy: 0.8118 - val_loss: 0.9469 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8213\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94687, saving model to retina_weights.best.hdf5\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 48s 643ms/step - loss: 0.8499 - categorical_accuracy: 0.7963 - top_2_accuracy: 0.8865 - val_loss: 0.8446 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94687 to 0.84463, saving model to retina_weights.best.hdf5\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 48s 647ms/step - loss: 0.7802 - categorical_accuracy: 0.7913 - top_2_accuracy: 0.9149 - val_loss: 0.8305 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.84463 to 0.83045, saving model to retina_weights.best.hdf5\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 49s 649ms/step - loss: 0.8569 - categorical_accuracy: 0.7470 - top_2_accuracy: 0.8956 - val_loss: 0.8227 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.83045 to 0.82272, saving model to retina_weights.best.hdf5\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 48s 640ms/step - loss: 0.8003 - categorical_accuracy: 0.7719 - top_2_accuracy: 0.9122 - val_loss: 0.8211 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82272 to 0.82110, saving model to retina_weights.best.hdf5\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 48s 641ms/step - loss: 0.8070 - categorical_accuracy: 0.7566 - top_2_accuracy: 0.9155 - val_loss: 0.8227 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.82110\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 48s 647ms/step - loss: 0.8119 - categorical_accuracy: 0.7603 - top_2_accuracy: 0.8976 - val_loss: 0.8245 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.82110\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 48s 646ms/step - loss: 0.8780 - categorical_accuracy: 0.7161 - top_2_accuracy: 0.9123 - val_loss: 0.8223 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.82110\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 48s 643ms/step - loss: 0.8491 - categorical_accuracy: 0.7476 - top_2_accuracy: 0.9028 - val_loss: 0.8236 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.82110\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 48s 649ms/step - loss: 0.8067 - categorical_accuracy: 0.7563 - top_2_accuracy: 0.9230 - val_loss: 0.8255 - val_categorical_accuracy: 0.7653 - val_top_2_accuracy: 0.8907\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.82110\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8255 - categorical_accuracy: 0.7653 - top_2_accuracy: 0.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8255048990249634, 0.765333354473114, 0.890666663646698]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = retina_model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    callbacks = callbacks_list,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "retina_model.evaluate(testing_images, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "further-party",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  [0.7440000176429749, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873, 0.7493333220481873]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "from_bounds() argument after * must be an iterable, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f0a86250d452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dr/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dr/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;34m\"\"\"Create a new figure manager instance.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dr/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3491\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m         \u001b[0mfig_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FigureClass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3493\u001b[0;31m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3494\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dr/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             raise ValueError('figure size must be positive finite not '\n\u001b[1;32m    323\u001b[0m                              f'{figsize}')\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi_scale_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: from_bounds() argument after * must be an iterable, not int"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "print(\"acc : \",acc)\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "top_2_acc = history.history['top_2_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure(1000,1000)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Top Accuracy = \",max(top_2_acc)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "verbal-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/sdb/DATASETS/diabetic_retinopathy/rgb_model/assets\n"
     ]
    }
   ],
   "source": [
    "retina_model.load_weights(weight_path)\n",
    "retina_model.save('/mnt/sdb/DATASETS/diabetic_retinopathy/rgb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-reference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-maintenance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
